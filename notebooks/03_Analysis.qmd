
```{python}
import numpy as np
import pandas as pd
import seaborn as sns
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import warnings
import scienceplots
warnings.filterwarnings('ignore', category=FutureWarning)

# Set visualization style
sns.set_style("ticks")
sns.set_context("paper")
plt.style.use(['science']) 
sns.set_palette("deep")
plt.rcParams.update({'figure.dpi': '100'})
#plt.rcParams['figure.figsize'] = (10, 6)
#plt.rcParams['figure.dpi'] = 100
#plt.rcParams['font.size'] = 10

# Color palette for methods
#method_colors = {
#    'InteriorPoint': '#1f77b4',
#    'Manifold': '#ff7f0e', 
#    'QSA': '#2ca02c'
#}
```

```{python}
output_dir = Path("processed_data")
df = pd.read_csv(output_dir / "graph_symmetry_results_all.csv")
df.head()
```

- in this section we are goint to evaluate the experimental results from the numerical experiments, the numerical eperiments have bbe done on 3 types of synthetic data graph create d reandomlly with different parameters, ER, BA, LRM rewired

- - qap method will be the baseline and comparison method for all of the evaluations in this section
the thwo methods are naturally sperarated into two groups, the QAP manifold and interior point method are iterative methods. The SoftSort and orthogonal relaxation are temperature controledmethods and this means that 
1. second
2. third

# Experimental design

We will test out methods on synthetic data on graph instances of Erdos Renyi, Barabasi albert and LRM_Rew model on various parameter choices, we have 39 randomly generated graph simulations for every parameter configuration of the graphs. 

We will run each method on every simulation for a number of configuration
parameters. Each method will be initialized with a random point and each method
will be run with multiple restarts (we choose 5 restarts). Afterwards, the best
of 5 runs will be chosen (such that it is valid (i.e.) non-identity and achieves
the least symmetry error from all of the runs)


# QSA vs. Manifold, IP


in the first part we will compare the QSA, Manifold and Interiorpoint methods since they are iterative methods and work on a similar principle, while the softsort and OT4P4AS methods are temperature beased and we will look at them, together in the following section


```{python}
# Select out the QSA, Manifold and INteriorPoint methods for analysis
df_mi = df[df["method"].isin(["QSA", "Manifold", "InteriorPoint"])]
```

## Identity

First and foremost, it is important to check that the methods are valid, i.e.
that they givve results that we care about, as we mentioned previously, we do
not care about the identity solution, since it is a non-informative trivial
solution that is available always and tells us nothing.

In the following figure we look at the influence of the c parameter on the
validity of the solution, i.e. how many simulations (instances) were solved
successfully.


```{python}
# Success rate: How many instances were solved successfully (a non-identity solution was found)
# GOLDEN GRAPH USE THIS

# This cell creates a figure for each graph type and compares the success rate
# for every method (i.e. the proportion of instances that have at least one run
# that was non-identity)

hlp = df_mi.copy()
hlp = hlp.assign(not_identity=hlp["n_nodes"] != hlp["fixed_points"])
hlp = (
    hlp.groupby(["density", "method", "graph_type", "n_nodes", "rew", "c", "sim_id"], dropna=False)["not_identity"]
    .agg(success="any")
    .reset_index()
)
hlp = (
    hlp.groupby(["density", "method", "graph_type", "n_nodes", "rew", "c"], dropna=False)["success"]
    .value_counts(normalize=True)
    .unstack(fill_value=0)
    .reset_index()
)
hlp = hlp.melt(
    id_vars=["density", "method", "graph_type", "n_nodes", "rew", "c"],
    value_vars=[True, False],
    var_name="outcome",
    value_name="proportion"
)
hlp = hlp[hlp["outcome"] == True]

hlp_lrm = hlp.query('graph_type == "LRM_ER"')
hlp_ba_er = hlp.query('graph_type != "LRM_ER"')

for graph_type in graph_types:
    hlp_graph_type= hlp[hlp["graph_type"] == graph_type]
    g= sns.relplot(
        data=hlp_graph_type,
        x='c', 
        y='proportion', 
        hue='method', 
        style="rew" if graph_type == "LRM_ER" else "graph_type", 
        row="n_nodes", 
        col="density", 
        kind="line",
        markers=True,
        #dodge=True,
        #errorbar=None
    )
    g.set(ylim=(0, None))
    g.fig.suptitle(graph_type)
```

What the above graph shows is that the QSA and Manifold instances are quite good
behaved (well this might not be good behaved it might just mean that the methods
were not able to find the trivial identity solution even when low penalization
was given, it can actually mean that the methods are too weak to find even the
trivial solution given random initial starting position and they get stuck
somewhere in a local minimum) when it comes to the choice of parameter `c` and
they do not converge to identity even for low values of `c`. This is true for
graph types for QSA and Manifold. WHen we talk about InteriorPoint method it is
however a different story, We can see that apart from LRM_ER it a significant
number of simulations have yielded only identity solutions. Compared to QSA and
Manifold, the `c` parameter had to be set much higher to achieve a that the
method finds a non-identity solution. For the BA (barabasi albert) graph type
even the highest tried value `c=1.0` was not enough to guarantee all instances
were found with non-identity solution. 

Overall it can be seen that given a higher density of edges, the methods have
more trouble with finding a non-identity solution so this suggest that fi the
graphs have higherr number of edges it is more diffuctult for the methods to
find a non-trivial symmetry which meets the expectations.

## Iterations

another degenerate ccase that miught happen when solving the appproxiumate
symmetry poroblem with the methods is when there is not enough iterations left
so that the optimal solution is found or thata the method is set so that we do
not have enough time for the full solution (local optimum) to be fou. This might
be caused either by the fiddifulty of the instance or that the method is bad. We
care to look at these cases because it is important to note that to know that
our methods are converging or they are not being able to converge in the
allocated number of iterations. Of course the number of iterations dirrectly
correlates to the running time albeit the time for one iteration is much smaller
for first order methods then second order methods like interior point as
explained in the interior point chapter.


in the following plot we plot the number of number of iterations of all runs for
each method. Do note the spike at 500 which is the upper bound on iterations which denotes the that the method was not able to converge in the allocated iteration time.


```{python}
# Question: What is the number of iterations the method takes until it finds a solution (or stops)?

# Distribution of max iterations

sns.displot(
    data=df_mi,
    x="metric_iterations",
    hue="method",
    multiple="stack",
    col="method",
    row="graph_type",
    kind="hist",
    stat="proportion",
    bins=30,
)
```

We can see that although the distribution of the iterations seams to be
decreasing, there there seem to be graph instantces that are hard to compute or
solve and require a high number of iterartions. In the next graph we will look
at the distribution of the exceeeded iterations runs separated into different
graph types and also with faceted out parameters like density and the number of
nodes


The following figure depicts the distribution of max iteration runs. The
proportions are normalized over each method and graph type (i.e. for each method
and graph type we can see the proportion of unsuccessful runs for each
configuration of graph instance (n_nodes, density)). We can see that the Manifold method, does have very nice convergence properties for all graph types.
The QSA and interior point methods do seem to struggle a bit. The QSA method does seem to behave in a more balanced way meaning that it does seems to over-iterate on all graph types in a same way, the number of over-iterations seems to increase as the number of nodes increases. 
THe interior point tmethod seems to be a bit more erratic. In a sense where instances considered "harder" (higher density, higher number of nodes) do no necessarily mean over-iterated instances. This can be caused by the fact that the method recognizes the difficulty of the instance and gets stuck in a local minimum much faster, wheres for an easier instance it does not give up so easily and tries to look for another way to find a solution. This is shown in the data in the figure below.

```{python}
from itertools import product
# =====================================================
# DATA PREPARATION AND FILTERING
# =====================================================

# Create working copy of original dataframe
hlp = df_mi.copy()

# Create convergence indicator
hlp['converged'] = (hlp["method_max_iter"] == hlp["metric_iterations"]).astype(int)

# Calculate convergence rate directly
prop_data = (hlp.groupby(['method', 'graph_type', 'n_nodes', 'density'])['converged']
             .agg(['mean', 'count'])
             .reset_index()
             .rename(columns={'mean': 'proportion', 'count': 'total_runs'}))

# =====================================================
# CREATE SUBPLOT LAYOUT FOR HEATMAPS
# =====================================================

# Create grid: methods as rows, graph_types as columns
# Each cell will be a heatmap showing n_nodes vs density for that method-graph_type combination
fig, axes = plt.subplots(len(methods), len(graph_types), 
                        figsize=(4*len(graph_types) + 2, 4*len(methods)))

# Handle edge cases where we have only one row or column
# matplotlib returns 1D array for single row/column, but we need 2D for consistent indexing
if len(methods) == 1:
    axes = axes.reshape(1, -1)
if len(graph_types) == 1:
    axes = axes.reshape(-1, 1)

# =====================================================
# DETERMINE COLOR SCALE RANGE
# =====================================================

# Find global min/max across all data to ensure consistent color mapping
# This makes proportions comparable across all subplots
vmin = prop_data['proportion'].min()
vmax = prop_data['proportion'].max()

# =====================================================
# GENERATE HEATMAPS FOR EACH METHOD-GRAPH_TYPE COMBINATION
# =====================================================

im = None  # Will store the last heatmap object for colorbar creation

for i, method in enumerate(methods):
    for j, graph_type in enumerate(graph_types):
        # Filter data for this specific method-graph_type combination
        subset = prop_data[(prop_data['method'] == method) & 
                          (prop_data['graph_type'] == graph_type)]
        
        # Reshape data into matrix format for heatmap
        # Rows = density values, Columns = n_nodes values, Values = proportions
        heatmap_data = subset.pivot(index='density', columns='n_nodes', values='proportion')
        
        # Create heatmap with annotations showing exact proportion values
        im = sns.heatmap(
            heatmap_data, 
            ax=axes[i,j], 
            annot=True,           # Show proportion values in cells
            fmt='.3f',           # Format numbers to 3 decimal places
            vmin=vmin, vmax=vmax, # Use consistent color scale across all subplots
            cbar=False           # Disable individual colorbar (we'll add one global colorbar)
        )
        
        # Add descriptive title and axis labels for each subplot
        axes[i,j].set_title(f'{method} - {graph_type}')
        axes[i,j].set_xlabel('n_nodes')
        axes[i,j].set_ylabel('density')

# =====================================================
# ADD SINGLE COLORBAR FOR ALL SUBPLOTS
# =====================================================

# Adjust layout to make room for colorbar on the right
plt.tight_layout()

# Create single colorbar spanning all subplots
# This shows the proportion scale that applies to all heatmaps
cbar = fig.colorbar(im.get_children()[0], ax=axes, shrink=0.8, aspect=30)
cbar.set_label('Proportion (normalized within method)', rotation=270, labelpad=15)

# Display the complete visualization
plt.show()

# =====================================================
# VERIFICATION (OPTIONAL)
# =====================================================

# Verify that proportions sum to 1.0 within each method
print("Proportion sums per method (should all be 1.0):")
print(prop_data.groupby('method')['proportion'].sum())
```


## Symmetry

Next we take our eyes to the study of actually symemtry or in other words how
good is the symmetry of the solutions we have found for the methods.


Firstly in the following figure we are going to look how does the value of the
`c` parameter affect the resulting symmetry. Note that from now on We will
consider only the simulations that have found a nontrivial solution (non-identity).


```{python}
# QUestion: Does the value of c affect symmetry

# DESCRIPTION : This figure plots the value of the symmetry coefficient for the QSA, Manifold, and InteriorPoint methods for all graph types and combinations of parameters (graph types are in different rows, number of nodes in columns (increasing) and the density parameters are differentiated by line styles (full line is density 15 and dashed line is density 40))

hlp = df_mi.copy()
hlp = hlp[hlp["n_nodes"] != hlp["fixed_points"]]
hlp = (
    hlp.groupby(["density", "method", "graph_type", "n_nodes", "rew", "c", "sim_id"], dropna=False)["symmetry"]
    .agg("min")
    .reset_index()
)

hlp_lrm = hlp.query('graph_type == "LRM_ER"')
hlp_ba_er = hlp.query('graph_type != "LRM_ER"')

sns.relplot(
    data=hlp_ba_er,
    x="c",
    y="symmetry",
    kind="line",
    markers=True,
    errorbar='ci',
    style="density",
    col="n_nodes",
    row="graph_type",
    hue="method",
    #dodge=True,
    aspect=1,
)

sns.relplot(
    data=hlp_lrm,
    x="c",
    y="symmetry",
    kind="line",
    markers=True,
    errorbar='ci',
    style="density",
    row="n_nodes",
    col="rew",
    hue="method",
    #dodge=True,
    aspect=1,
)
```


One apparent trend is that the value of symmetry for higher density graphs is
generally higher than lower density for all values of `c`. There seems to be a
slight increase of symmetry error with with increasing value of `c` which then
stagnates and seems to even out (i.e. after some point the penalization does not
seem to have much effect). There seems to be  an increasing trend for the ER and
BA graphs w.r.t increasing value of c. This might seem to show that lower values
of c yield better symmetry. This is however highly skewed, since lower values of
c also yield a much higher rates of trivial solutions (compare with figure
above). So, it might be true that we achieve better results, but at a cost of
higher error rates. However, this might be circumvented with a higer number of
restarts and hoping for a nontrivial solution, which in turn might be better.
We would like a robus and reliable mathod so I view the high number of
identities values of c as detrimental and bad and prefer a values of c that lead
to a more robus solution approaches.


The following figure chooses the best value of c and compares the methods for
this one particular version. The best values is meant by a value such that we
look at number of non-trivial simulations. From those we choose the values of c
that resulted in the highest number of sucesses. From those values of c we take
the lowest one (since lower values of c seem to suggest better symmetry values
from the observed data). We do this for everymethod to find the optimal value of
c for every method.

In the following figure we compare the performance for the optimal settings for
all instances graph types, densities and number of nodes faceted. Note that a
lower symmetry number is better. We can observe a general trend that the
symmetry metric increases with the increasing number of nodes and density which
is as expected. We also see that out methods are comparable with the state of
the art QSA method. We see trend that the interior point methods does
out-perform the QSA method on most instance graph configurations. It is even
able to achieve perfect symmetry for the LRM graph with 0 rewires. 

On the other hand the manifold method does not bring increased quality of
solutions and underperforms both the interiror point and QSA methods (althought
not significantly).

```{python}
# OBJECTIVE: Find optimal 'c' parameter for each method that maximizes simulation success rate
# Success is measured by having complete data (non-NaN symmetry values)

# Question: What is the comparison of different 
# Plot the symmetry for a fixed c value, take the best solution across all runs in a simulation
# Issue: this plot has the issue that it shows only a single value of c which is chosen arbitrarily

# Data preparation: filter and aggregate to simulation level
hlp = df_mi.copy()
hlp = hlp[hlp["n_nodes"] != hlp["fixed_points"]]  # Remove degenerate cases

# Get minimum symmetry per simulation (one value per unique parameter combination + sim_id)
hlp = (
    hlp.groupby(["density", "method", "graph_type", "n_nodes", "rew", "c", "sim_id"], dropna=False)["symmetry"]
    .agg("min")
    .reset_index()
)

# OPTIMIZATION: Find best 'c' value per method based on simulation success count
# Count successful simulations (complete data points) for each method-c combination
simulation_counts = (
    hlp.groupby(["method", "c"])
    .size()
    .reset_index(name='successful_simulations')
)

# Find maximum success count achieved by each method
max_success_per_method = (
    simulation_counts
    .groupby('method')['successful_simulations']
    .max()
    .reset_index()
    .rename(columns={'successful_simulations': 'max_success'})
)

# Identify all method-c combinations that achieve maximum success for their method
candidates = simulation_counts.merge(max_success_per_method, on='method')
optimal_candidates = candidates[
    candidates['successful_simulations'] == candidates['max_success']
]

# Among tied optimal candidates, select minimum 'c' (most conservative parameter)
optimal_params = (
    optimal_candidates
    .groupby('method')['c']
    .min()
    .reset_index()
)

print(f"Optimal parameters per method:\n{optimal_params}")

# FILTERING: Keep only data points using optimal parameters
filtered_hlp = hlp.merge(optimal_params, on=["method", "c"], how='inner')

hlp_lrm = filtered_hlp.query('graph_type == "LRM_ER"')
hlp_ba_er = filtered_hlp.query('graph_type != "LRM_ER"')

# VISUALIZATION: Compare symmetry across conditions using optimal parameters only
sns.catplot(
    data=hlp_ba_er,  # Note: using filtered data with optimal parameters
    x="n_nodes",
    y="symmetry", 
    kind="box",
    row="graph_type",
    col="density",
    hue="method",
    aspect=1,
    dodge=True,
)

sns.catplot(
    data=hlp_lrm,  # Note: using filtered data with optimal parameters
    x="rew",
    y="symmetry", 
    kind="box",
    col="n_nodes",
    row="density",
    hue="method",
    aspect=1,
    dodge=True,
)
```

What I can see from the graphs is that the interiorpoint and manifold methods
are comparable to the established QSA method. One thing that stands out is that
the interior point method drasticvally outperforms both QSA and Manifold methods
for the LRM_REW graph type, where it actually is able to find the perfect
symmetry. 



# QSA vs. SoftSort and Orthogonal Relaxation

we now move to the comparison of the softsort method and the orthogonal relaxation methods.

these methods are different in that they are temperature controlled and it makes
sense to compare them together. 

It also makes sense to perform simmulated annealing on them (cosine temperature annealing scheme, Softsort 10.0 -> 0.1; OT4P4AS 0.7 -> 0.3 tau ranges)

```{python}
df_so = df[df["method"].isin(["SoftSort", "OT4P4AS"])]
df_so = df_so[~((df_so["method"] == "SoftSort") & (df_so["method_max_iter"] == 3000))]
df_so = df_so.assign(is_anneal=lambda _: ~_['method_final_tau'].isna())
df_so = df_so.assign(method_loss_combined=df_so['method'] + '/' + df_so['method_loss'])
df_so.head()
```

## Iterations

In this section we will look at the iterations of the indivisual methods, how many do we need them and how are they affected by the choice of loss and the graph instance for which graph instance do the methods perform better and for which graph instance the methods perofrm worse. 

In the following figuras we can see the distribtution of max iterations for different graph types and 

We can see that for both the softsort method and orthoghonal relaxation the convex loss does seem to perform much better with regards to the number of iterations needed until the best result is found (i.e. how many iterations do we need until we find the best result and after that the scheme does not seem to find a better result). For the indefinite relaxation it looks like in many cases the best solution is found at the end of the iterations when we cut the method (due to max iterations bound). Note that the methods are computationally intensive and the maximum number of iterations is quite generous concerning time compared to the methods in previous section.

We can also see an interesting phenonon in the indefinite case when comparing softsort and orthogonal relaxation. In both versions the tau parameter denotes the degree of relaxation (lower temperature the more strict we are), however the indefinite relaxation seems to have much harder time of finding a good solution for softsort (i.e. the number of best iterations are concentrated near the end of the allowed iteration spectrum) and this number decreases with increasing tau. This relationship is exactly switched for the orthogonal relaxation (indfinite case) where it seems that we are able to find a good enough solution before we run out of iteration budget and this number increases as we increase tau.


We have multiple hypothesis why this might happen. It can be the case that softsort does not have enough needs a bigger step size and for lower temperatures it converges much too slowely to find a satistying solution which leadas to a continouous improvement througout the iterations and the increasisng temperature might seem to 

```{python}
# QUESTION: How many iterations are required until the (optimal) best solution is found.
# Question: Does tau affect how many instances are solved to optimality?
hlp = df_so.query('~is_anneal')

methods = hlp['method'].unique()
for method in methods:
    display(method)
    hlp_method = hlp[hlp['method'] == method]
    g = sns.displot(
        data=hlp_method,
        x='metric_best_iteration',
        col="method_initial_tau",
        row="method_loss",
        hue="graph_type",
        kind="hist",
        multiple="stack",
    )
    st = g.fig.suptitle(method)

    g.fig.canvas.draw()

    # 2. Get the title's bounding box in pixel coordinates
    bbox = st.get_window_extent()

    # 3. Convert the bounding box to figure coordinates (0-to-1 range)
    fig_bbox = bbox.transformed(g.fig.transFigure.inverted())

    # 4. Get the top of the title's bounding box
    title_top = fig_bbox.y1

    # 5. Set the subplot's top margin to be just below the title
    #    We add a little padding (e.g., 0.02) for aesthetic spacing.
    g.fig.subplots_adjust(top = title_top - 0.08)
```


In the next figure we compare the effects of definite and indefinite relaxation
(loss functions) and the quality of the solution (quality of the symmetry). We
are tryting to challenge the asseumtpiton that the indefinite relaxation is the
better choice for the apprpxoimate symmetry problem .


The figure also depics the effect of chaning tau on the quality of the solution.
We see that the changing tau, does generally seem to decrease the quality of the
soluton (we find worse symmetries) than for lower tau values

The follwoignt fiture does seem tot indeed indicate that the convex relaxation
seems to produce a better quality result that the indefinite relaxation. 

However, do note that the indefinite relaxation did suffer from not enough
iterations (and the method wanted more iterations as we were stopping it early
when it still was increasing solution quality) this might be due to the fact of
bad configuration of the method and solver parameters which is subject to
further research.



```{python}
# Compare symmetry performance of different methods for different graph types
hlp = df_so.query('~is_anneal')
group_vars = ["method", "graph_type", "n_nodes", "density", "method_loss", "method_initial_tau"]

# Take only non identity
hlp = hlp[hlp["n_nodes"] != hlp["fixed_points"]]

# Take the best one from each simulation
hlp = hlp.groupby(group_vars + ["sim_id"])['symmetry'].agg('min').reset_index()
display(hlp)

methods = hlp["method"].unique()
graph_types = hlp["graph_type"].unique()
for method in methods:
    hlp_method = hlp[hlp["method"] == method]
    for graph_type in graph_types:
        hlp_method_graph_type = hlp_method.query(f"graph_type == '{graph_type}'")
        g = sns.catplot(
            data=hlp_method_graph_type,
            y="symmetry",
            x="method_initial_tau",
            hue="method_loss",
            row="density",
            col="n_nodes",
            kind="box",
        )
        st = g.fig.suptitle(f"{method} --- {graph_type}")

        # 1. Force a canvas draw to calculate the bounding box of the title
        g.fig.canvas.draw()

        # 2. Get the title's bounding box in pixel coordinates
        bbox = st.get_window_extent()

        # 3. Convert the bounding box to figure coordinates (0-to-1 range)
        fig_bbox = bbox.transformed(g.fig.transFigure.inverted())

        # 4. Get the top of the title's bounding box
        title_top = fig_bbox.y1

        # 5. Set the subplot's top margin to be just below the title
        #    We add a little padding (e.g., 0.02) for aesthetic spacing.
        g.fig.subplots_adjust(top = title_top - 0.05)
```

## Identity

Same as in the previous case we first need to check how it is with non informative, trivial identity solutions. Looking at the data we, however find out that these methods did not find identity solution in any of the cases and we can safely disregard it. This might be the side effect of the temperature controlled environment or that the landscape of the solver traverses is too diffictult  to even arrive at the identity solution.

```{python}
# Success rate: How many instances were solved UNsuccessfully (a identity solution was found)
# GOLDEN
hlp = df_so.query('~is_anneal')
group_vars = ["method", "graph_type", "n_nodes", "density", "method_loss", "method_initial_tau"]
hlp = hlp.assign(not_identity=hlp["n_nodes"] != hlp["fixed_points"])
hlp = (
    hlp.groupby(group_vars + ["sim_id"])["not_identity"]
    .agg(success="any")
    .reset_index()
)
hlp = (
    hlp.groupby(group_vars)["success"]
    .value_counts(normalize=True)
    .unstack(fill_value=0)
    .reset_index()
)
hlp = hlp.melt(
    id_vars=["density", "method", "graph_type", "n_nodes", "method_loss"],
    value_vars=[True, False],
    var_name="outcome",
    value_name="proportion"
)
hlp = hlp[hlp["outcome"] == True]
hlp.query('proportion < 1')
```

This information leads us to the fact where we can choose the convex relaxation as the dominant 

We will now add the data for the annealing case and look at the 

```{python}
# TASK: Best configuration
# SoftSort -> 0.1
# OT4P4AS -> 0.7
# Convex loss for both
hlp_so_best = (
    df_so
    .query("~is_anneal")
    .query("(method == 'SoftSort' & method_initial_tau == 0.1) | (method == 'OT4P4AS' & method_initial_tau == 0.7)")
)


```

Int the following we see that the annealing does not really have positive effect on the methods, in fact for the softsort it is consistabtly leading to worse results.

```{python}
# Question: Does annealing have possitive effect on the performance of the methods?
hlp = pd.concat([hlp_so_best, df_so.query("is_anneal")])

hlp = hlp[hlp["n_nodes"] != hlp["fixed_points"]]  # Remove degenerate cases

# Get minimum symmetry per simulation (one value per unique parameter combination + sim_id)
hlp = (
    hlp.groupby(
        [
            "method",
            "method_loss",
            "is_anneal",
            "graph_type",
            "density",
            "n_nodes",
            "sim_id",
        ]
    )["symmetry"]
    .agg("min")
    .reset_index()
)

hlp = hlp.assign(
    method_id=lambda _: _["method"]
    + "_"
    + _["method_loss"]
    + "_"
    + np.where(_["is_anneal"], "Anneal", "No-Anneal")
)

methods = hlp["method"].unique()
for method in methods:
    hlp_method = hlp[hlp["method"] == method]
    g = sns.catplot(
        data=hlp_method,
        y="symmetry",
        x="n_nodes",
        hue="method_id",
        col="graph_type",
        row="density",
        kind="box",
    )
    st = g.fig.suptitle(f"{method}")

    # 1. Force a canvas draw to calculate the bounding box of the title
    g.fig.canvas.draw()

    # 2. Get the title's bounding box in pixel coordinates
    bbox = st.get_window_extent()

    # 3. Convert the bounding box to figure coordinates (0-to-1 range)
    fig_bbox = bbox.transformed(g.fig.transFigure.inverted())

    # 4. Get the top of the title's bounding box
    title_top = fig_bbox.y1

    # 5. Set the subplot's top margin to be just below the title
    #    We add a little padding (e.g., 0.02) for aesthetic spacing.
    g.fig.subplots_adjust(top=title_top - 0.05)
```

